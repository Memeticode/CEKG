{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on: https://github.com/tomasonjo/blogs/blob/master/youtube/video2graph.ipynb\n",
    "\n",
    "Uses newspaper3k: https://pythonrepo.com/repo/codelucas-newspaper-python-web-crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import newspaper\n",
    "import openai\n",
    "import tiktoken\n",
    "from secret_credentials import OPENAI_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo\"):\n",
    "  \"\"\"Returns the number of tokens used by a list of messages.\"\"\"\n",
    "  try:\n",
    "      encoding = tiktoken.encoding_for_model(model)\n",
    "  except KeyError:\n",
    "      encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "  if model == \"gpt-3.5-turbo\":  # note: future models may deviate from this\n",
    "      num_tokens = 0\n",
    "      for message in messages:\n",
    "          num_tokens += 4  # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n",
    "          for key, value in message.items():\n",
    "              num_tokens += len(encoding.encode(value))\n",
    "              if key == \"name\":  # if there's a name, the role is omitted\n",
    "                  num_tokens += -1  # role is always required and always 1 token\n",
    "      num_tokens += 2  # every reply is primed with <im_start>assistant\n",
    "      return num_tokens\n",
    "  else:\n",
    "      raise NotImplementedError(f\"\"\"num_tokens_from_messages() is not presently implemented for model {model}.\n",
    "  See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set openai system prompt\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "prompt_system = '''You are an expert financial, economic, and political analyst helping to read news articles and extract relevant information (entities and relationships) into a knowledge and current events graph. As input, you will accept the text of a news article. The first line of the input will always be the article headline. You will generate output that contains three sections:\n",
    "entity - All relevant entities (related to finance, the economy, or politics), labeled with an appropriate descriptive category. Each entity is written on its own line as “LABEL {Entity Name}”\n",
    "relationship - All direct relationships between the extracted entities. Each relationship is written on its own line as: “{Head Entity Name} RELATIONSHIP {Tail Entity Name}”\n",
    "current_event - All news items (actions or events described in the article that involve one or more of the extracted entities but are not simple direct relationships), along with the associated entities (only reference entities which you have previously defined in the first section). Each event and associated entities is written on its own line as “NEWS_ITEM {Entity 1} {Entity 2} {…} {Entity n}”\n",
    "\n",
    "To help you understand the requirements, here is an example:\n",
    "INPUT\n",
    "DeSantis threatens Disney with legal retaliation\n",
    "Florida Governor Ron DeSantis escalated the state's ongoing legal battle with Disney for control over their special district in Orlando, Florida.\n",
    "\n",
    "OUTPUT\n",
    "entity:\n",
    "PLACE {Florida} \n",
    "PLACE {Orlando}\n",
    "PERSON {Ron DeSantis}\n",
    "COMPANY {Disney}\n",
    "PLACE {Disney Special District}\n",
    "\n",
    "relationship:\n",
    "{Ron DeSantis} GOVERNOR_OF {Florida}\n",
    "{Disney} OWNS {Disney Special District}\n",
    "{Disney Special District} IN {Orlando}\n",
    "{Orlando} IN {Florida} \n",
    "\n",
    "current_event:\n",
    "ONGOING_LEGAL_BATTLE {Florida} {Disney} {Ron DeSantis} {Disney Special District}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download article\n",
    "#cnn_paper = newspaper.build('http://cnn.com')\n",
    "#articles = [article for article in cnn_paper.articles] # if \"business\" in article.url] # and article.url.endswith(\"index.html\")\n",
    "article = newspaper.Article(\"https://www.cnn.com/2023/04/06/tech/korea-samsung-chips-cuts-hnk-intl/index.html\")\n",
    "article.download()\n",
    "article.parse()\n",
    "\n",
    "prompt_input = article.title + \"\\r\\n\" + article.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "882"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_messages=[\n",
    "        {\"role\": \"system\", \"content\": prompt_system},\n",
    "        {\"role\": \"user\", \"content\": prompt_input}\n",
    "    ]\n",
    "num_tokens_from_messages(prompt_messages, \"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=prompt_messages,\n",
    "  temperature=0 #most deterministic\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "restext = response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity:\n",
      "COMPANY {Samsung Electronics}\n",
      "PRODUCT {memory chips}\n",
      "COMPANY {SK Hynix}\n",
      "PRODUCT {TV}\n",
      "PLACE {Seoul}\n",
      "TIME {January-March 2019}\n",
      "\n",
      "relationship:\n",
      "{Samsung Electronics} IS_WORLD'S_LARGEST {memory chip and TV maker}\n",
      "{Samsung Electronics} OWNS {memory chips}\n",
      "{SK Hynix} IS_RIVAL_OF {Samsung Electronics}\n",
      "{memory chips} ARE_PRODUCED_IN {Seoul}\n",
      "\n",
      "current_event:\n",
      "CHIP_PRODUCTION_CUT {Samsung Electronics}\n",
      "DECLINE_IN_MEMORY_DEMAND {Samsung Electronics}\n",
      "DECLINE_IN_SEMICONDUCTOR_BUYERS {data center operators, smartphone and personal computer makers}\n",
      "INVENTORY_ADJUSTMENT {Samsung Electronics}\n"
     ]
    }
   ],
   "source": [
    "for line in restext.split('\\n'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
